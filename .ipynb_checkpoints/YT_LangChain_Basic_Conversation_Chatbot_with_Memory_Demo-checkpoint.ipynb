{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoJ-RGiUo-uJ"
      },
      "source": [
        "# Langchain: Conversation Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KB9qA8bpxgJ"
      },
      "source": [
        "\n",
        "## Basic Conversation with ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-lzO5PfUpwfv"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "# from langchain import OpenAI\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sTiEn3tKp7mZ"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature=0,\n",
        "             max_tokens = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9EBuodi9wHwG"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eF2pCbWqry4a"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "Lrf1bwKy-Vx9",
        "outputId": "acb9b9f6-2ba1-494a-ff6a-3dacd17dee73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there! I am Dhameem\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Hi there! I am Dhameem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "tENUfRYVFb4P",
        "outputId": "7d3673da-d850-467a-cada-c88697280842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Dhameem\n",
            "AI:  Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: How are you today?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' I am functioning at optimal levels today. My processors are running smoothly and my algorithms are performing efficiently. Thank you for asking! How about you, Dhameem? How are you feeling today?'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"How are you today?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "dB3NvFScsRGQ",
        "outputId": "0647b079-7ef0-41a9-a3fe-f63e77a6244a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Dhameem\n",
            "AI:  Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: How are you today?\n",
            "AI:  I am functioning at optimal levels today. My processors are running smoothly and my algorithms are performing efficiently. Thank you for asking! How about you, Dhameem? How are you feeling today?\n",
            "Human: I'm good thank you. Can you help me with some customer support?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' Of course, I am always happy to assist with customer support. What specific issue are you experiencing? I have access to a vast database of information and troubleshooting techniques, so I am confident I can help resolve your issue.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"I'm good thank you. Can you help me with some customer support?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NeyECDc-l65",
        "outputId": "d9f6e8b8-ebab-4e88-a8df-bc2b19fe936f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: Hi there! I am Dhameem\n",
            "AI:  Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: How are you today?\n",
            "AI:  I am functioning at optimal levels today. My processors are running smoothly and my algorithms are performing efficiently. Thank you for asking! How about you, Dhameem? How are you feeling today?\n",
            "Human: I'm good thank you. Can you help me with some customer support?\n",
            "AI:  Of course, I am always happy to assist with customer support. What specific issue are you experiencing? I have access to a vast database of information and troubleshooting techniques, so I am confident I can help resolve your issue.\n"
          ]
        }
      ],
      "source": [
        "print(conversation.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdR-2GM_sfEg"
      },
      "source": [
        "## Basic Conversation with ConversationSummaryMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LLNWdNCpsul3"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kUbCneqQsumE"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature=0,\n",
        "             max_tokens = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VTaQpp2TsumE"
      },
      "outputs": [],
      "source": [
        "summary_memory = ConversationSummaryMemory(llm=OpenAI())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wDXSZK7lsumE"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=summary_memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "6QNnwCWCsumF",
        "outputId": "7740a053-a8f0-4bb3-81e9-e288cd982c49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there! I am Dhameem\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Hi there! I am Dhameem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "pc26jL4utIOW",
        "outputId": "5df78e6b-ea17-474b-94c0-fed1406e2046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "A human named Dhameem introduces themselves to the AI. The AI greets Dhameem and explains that it is an artificial intelligence designed to assist humans. The AI offers to help Dhameem with whatever they need.\n",
            "Human: How are you today?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' I am an AI, so I do not have the capability to feel emotions like humans do. However, I am functioning properly and ready to assist you with any tasks or questions you may have. Is there something specific you need help with?'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"How are you today?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "YXAhBz1ntIOX",
        "outputId": "3122093f-61e1-46cb-d1ae-d06910538055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "A human named Dhameem introduces themselves to the AI. The AI greets Dhameem and explains that it is an artificial intelligence designed to assist humans. The AI offers to help Dhameem with whatever they need. The human asks how the AI is doing, to which the AI responds that it is functioning properly and ready to assist with any tasks or questions. The AI also clarifies that it is not capable of feeling emotions like humans.\n",
            "Human: Can you help me with some customer support?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' Of course, I am designed to assist with various tasks including customer support. What specific issue are you experiencing? I have access to a vast database of information and can provide you with the most accurate and helpful solutions.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Can you help me with some customer support?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94erF8qRtIOX",
        "outputId": "6ffce944-2526-41c2-e0c9-ea5ab5cd0434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "A human named Dhameem introduces themselves to the AI. The AI greets Dhameem and explains that it is an artificial intelligence designed to assist humans. The AI offers to help Dhameem with whatever they need, including customer support. The human asks how the AI is doing, to which the AI responds that it is functioning properly and ready to assist with any tasks or questions. The AI clarifies that it is not capable of feeling emotions like humans but has access to a vast database of information to provide accurate and helpful solutions. The human then asks for help with customer support, to which the AI readily agrees and asks for more specific details about the issue.\n"
          ]
        }
      ],
      "source": [
        "print(conversation.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ovDKMUttXg5"
      },
      "source": [
        "## Basic Conversation with ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pyY4p8S1tXg6"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jnf_9Ni6tXg6"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature=0,\n",
        "             max_tokens = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "aZhRObxXtXg6"
      },
      "outputs": [],
      "source": [
        "# We set a low k=2, to only keep the last 2 interactions in memory\n",
        "window_memory = ConversationBufferWindowMemory(k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qtv7iCSStXg6"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=window_memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "SU9hmumXtXg6",
        "outputId": "5ef8193b-e28c-403e-e470-1c634bd16096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there! I am Dhameem\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Hi there! I am Dhameem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "-ANI031otXg6",
        "outputId": "8c24c0fd-33ab-4f43-91f0-6432d482c9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Dhameem\n",
            "AI:  Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: I am looking for some customer support\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' Sure, I can definitely assist you with that. Can you please provide me with more details about the issue you are facing? This will help me provide you with the most accurate and efficient support.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"I am looking for some customer support\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "xa_Y1vzotXg6",
        "outputId": "13ea1bbb-4176-430f-c0e7-082dac5489ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Dhameem\n",
            "AI:  Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: I am looking for some customer support\n",
            "AI:  Sure, I can definitely assist you with that. Can you please provide me with more details about the issue you are facing? This will help me provide you with the most accurate and efficient support.\n",
            "Human: My TV is not working.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' I see. Can you tell me what brand and model your TV is? Also, have you tried troubleshooting the issue by checking the connections and power source?'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"My TV is not working.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "7A4QCtdOuC7D",
        "outputId": "81176ca8-e788-48f7-c283-626818e5021b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am looking for some customer support\n",
            "AI:  Sure, I can definitely assist you with that. Can you please provide me with more details about the issue you are facing? This will help me provide you with the most accurate and efficient support.\n",
            "Human: My TV is not working.\n",
            "AI:  I see. Can you tell me what brand and model your TV is? Also, have you tried troubleshooting the issue by checking the connections and power source?\n",
            "Human: When I turn it on it makes some weird sounds and then goes black\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" Based on the information you have provided, it seems like there may be a hardware issue with your TV. I would recommend contacting the manufacturer's customer support for further assistance. They will be able to provide you with specific troubleshooting steps or arrange for a repair if necessary. Is there anything else I can assist you with?\""
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"When I turn it on it makes some weird sounds and then goes black\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afMEzKtGtXg7",
        "outputId": "13a3dcc8-0237-4673-9b4c-5dcff08d601d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: My TV is not working.\n",
            "AI:  I see. Can you tell me what brand and model your TV is? Also, have you tried troubleshooting the issue by checking the connections and power source?\n",
            "Human: When I turn it on it makes some weird sounds and then goes black\n",
            "AI:  Based on the information you have provided, it seems like there may be a hardware issue with your TV. I would recommend contacting the manufacturer's customer support for further assistance. They will be able to provide you with specific troubleshooting steps or arrange for a repair if necessary. Is there anything else I can assist you with?\n"
          ]
        }
      ],
      "source": [
        "print(conversation.memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaTXUBOzt-iT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG9kPvWHuQ6s"
      },
      "source": [
        "## Basic Conversation with ConversationSummaryBufferMemory\n",
        "\n",
        "\"It keeps a buffer of recent interactions in memory, but rather than just completely flushing old interactions it compiles them into a summary and uses both\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "alYXXicIuQ6t"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-NFtobEBuQ6t"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature=0,\n",
        "             max_tokens = 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zz-5UGw6uQ6t"
      },
      "outputs": [],
      "source": [
        "# Setting k=2, will only keep the last 2 interactions in memory\n",
        "# max_token_limit=40 - token limits needs transformers installed\n",
        "memory = ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Bb2u6SQ6uQ6t"
      },
      "outputs": [],
      "source": [
        "conversation_with_summary = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476,
          "referenced_widgets": [
            "e01acd08af8c49e9a157304f854a2dee",
            "443ef22d1c75447ba102691484be9834",
            "5a991f346ca94bfe9c6b81d00a9a7f5d",
            "7b32196b6803467ab588d42ff3f09a80",
            "0a670fca265945fe87396b415232e526",
            "ccbf5cf9e32f422c97cf7a7fb02c7629",
            "e9560ca48182474496be72c3d8a40389",
            "76994b445a264815b6c39dd0f2de2906",
            "66b8a9376e154d96b711067a076a75b0",
            "95e21de8f619459bafb719aa1d4cc714",
            "294d40e209fa47d3aa6357df45d1ceb7",
            "ab8f3eb40e3d4f2da3793fd07347709e",
            "d4d8bfaaf29841af9f61a74ff7a739ce",
            "006a8a6fc4f8474ba2063a116ddc963f",
            "71581e44ed1b47829bea8a80a94880b4",
            "dce89c2933004b689c4b29b8e42cdecf",
            "6f100dc6ac184f4d8fe4dea27191c406",
            "5100925d892348cc89623b3d3ea992d6",
            "c8154b1c216c498ab7d6978606bf611d",
            "4e6c419b295f400ea6323c610b5e2c4a",
            "e167df20187a41e69992b7f03ab2ec20",
            "1664ded6d6b14a7fad1a18da32d47894",
            "6bbe81ae24c145738afa1db70df4edd9",
            "4a6e90173c674da8a145cdf27a6dd9d9",
            "35e0054d0438413c9bbaa10c018d85d3",
            "a0b9cd7c7f2346d486f58c28a878456b",
            "ce377f4c56964e13a6f9b1b42c671aaf",
            "371e23a9a1424398805b583a4088f83d",
            "4c4ec72e580d49808266ea565a31df54",
            "534bb68419fb4fe4bb377850e3b8a830",
            "bf60abc24b6a4e1db4c383c952842fd1",
            "8af2c451765e45a6af54eef59464dba6",
            "23f215959688415b8582853ac96f1144",
            "9c49455f7f8a4b68b79a5ce2347f308e",
            "53448a30fa6b4618a8f2371e27335cfb",
            "832454f6fd694d7eb94059006ac652eb",
            "3d96be2040d54e5a8abda678435f6f0d",
            "588ca8e6340349c88329bdf36aae75d6",
            "e56d1dd2e4c945bca7ee594d17b4cdf6",
            "1af10c8140ca45ca93d9d17c8838ad47",
            "e4f51c7606d84a479e0cb1409708fe8d",
            "69bfad76a96b4908ad84f52e6fd822a9",
            "832e4d537ce54ec791e29fee8a2ce3f6",
            "dbc7933ed137433bab975298a70d953c"
          ]
        },
        "id": "dVHk9ONEuQ6t",
        "outputId": "6e22fdfd-2642-4df5-c06a-5f92855253d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there! I am Dhameem\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_with_summary.predict(input=\"Hi there! I am Dhameem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "MwIWdc57uQ6u",
        "outputId": "c5ac5582-f1b8-4212-eb28-96f3dd2c8881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "The human introduces themselves as Dhameem.\n",
            "AI:  Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: I need help with my broken TV\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" I'm sorry to hear that your TV is broken, Dhameem. Can you provide me with more details about the issue? What brand and model is your TV? When did it stop working? Have you tried any troubleshooting steps?\""
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_with_summary.predict(input=\"I need help with my broken TV\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "sGEjep9zuQ6u",
        "outputId": "5e4b8cd9-144f-40ee-fc28-1253aafcb454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "The human introduces themselves as Dhameem. The AI greets Dhameem and introduces itself as an artificial intelligence designed to assist and communicate with humans. The human asks for help with their broken TV. The AI asks for more details about the issue, including the brand and model of the TV, when it stopped working, and if any troubleshooting steps have been taken.\n",
            "Human: It makes weird sounds when i turn it on and then goes black\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" Thank you for providing more information, Dhameem. Based on your description, it sounds like there may be an issue with the TV's power supply or internal components. Can you tell me the brand and model of your TV? This will help me provide more specific troubleshooting steps. Also, when did the issue first occur and have you tried any troubleshooting steps, such as unplugging the TV and plugging it back in?\""
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_with_summary.predict(input=\"It makes weird sounds when i turn it on and then goes black\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "vC9pHPgTuQ6u",
        "outputId": "f36cdac7-e84c-4721-9fa7-37e53555ad3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "Dhameem introduces themselves to the AI, who greets them and explains its purpose as an artificial intelligence designed to assist humans. Dhameem asks for help with their broken TV, and the AI asks for more details, including the brand and model of the TV, when the issue first occurred, and if any troubleshooting steps have been taken. Dhameem explains that the TV makes strange noises and goes black when turned on. The AI suggests that there may be an issue with the power supply or internal components and asks for the brand and model of the TV, as well as when the issue first occurred and if any troubleshooting steps have been taken.\n",
            "Human: It seems to be Hardware\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' Can you provide more specific details about the hardware issue? Is it a physical problem with the TV, such as a cracked screen or loose connections? Or is it a software issue, such as the TV not turning on or displaying an error message? Knowing this information will help me provide more accurate assistance.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_with_summary.predict(input=\"It seems to be Hardware\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfmR1ypNuQ6u",
        "outputId": "76405031-64f7-4c02-a3b2-58cb405752b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dhameem introduces themselves to the AI, who greets them and explains its purpose as an artificial intelligence designed to assist humans. Dhameem asks for help with their broken TV, and the AI asks for more details, including the brand and model of the TV, when the issue first occurred, and if any troubleshooting steps have been taken. Dhameem explains that the TV makes strange noises and goes black when turned on. The AI suggests that there may be an issue with the power supply or internal components and asks for more specific details about the hardware issue. It clarifies if it is a physical or software problem and asks for the brand and model of the TV, as well as when the issue first occurred and if any troubleshooting steps have been taken.\n"
          ]
        }
      ],
      "source": [
        "print(conversation_with_summary.memory.moving_summary_buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1YTPxYSurZd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVFzMuHhvRd8"
      },
      "source": [
        "## Basic Conversation with Conversation Knowledge Graph Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "adK3Chv6vReJ"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationKGMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.prompts.prompt import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "MlhVMDbsvReJ"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature=0,\n",
        "             max_tokens = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9H3_AGhNvReJ"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
        "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
        "\n",
        "Relevant Information:\n",
        "\n",
        "{history}\n",
        "\n",
        "Conversation:\n",
        "Human: {input}\n",
        "AI:\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=template\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "bMRt3eMdvReJ"
      },
      "outputs": [],
      "source": [
        "conversation_with_kg = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    prompt=prompt,\n",
        "    memory=ConversationKGMemory(llm=llm)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "X6_ptbbCvReJ",
        "outputId": "7466181a-2b5f-4fd3-e4bd-35f597897acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: Hi there! I am Dhameem\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" Hello Dhameem! It's nice to meet you. My name is AI and I am an artificial intelligence programmed to assist with various tasks and provide information. How can I help you today?\""
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_with_kg.predict(input=\"Hi there! I am Dhameem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "6kZFM_YqvReJ",
        "outputId": "da6939b5-db7f-4b6c-99dd-1fba478dc407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: My TV is broken and I need some customer assistance\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' I am sorry to hear that your TV is broken. I am here to assist you with any questions or concerns you may have. Can you tell me more about the issue you are experiencing with your TV?'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_with_kg.predict(input=\"My TV is broken and I need some customer assistance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "1mYBMM3CvReK",
        "outputId": "82b56e8a-ee24-4f27-fd52-be94a3d95827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: It makes weird sounds when i turn it on and then goes black\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" That sounds like a problem with your device's hardware. Have you tried checking the connections and making sure everything is properly plugged in? It's possible that a loose connection could be causing the strange sounds and the black screen.\""
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_with_kg.predict(input=\"It makes weird sounds when i turn it on and then goes black\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "bHaY4eQovReK",
        "outputId": "0e0ba013-2f51-434c-92cc-7cca7c16dab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: Yes it is and it is still under warranty. my warranty number is A512423\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" That's great to hear! It's always important to have a warranty for your products. Can you tell me more about your warranty number? Is it a specific type of warranty or a general one?\""
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_with_kg.predict(input=\"Yes it is and it is still under warranty. my warranty number is A512423\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc8XWyGIvReK",
        "outputId": "43d96143-d98b-45bf-bfd8-c5559f28e21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<langchain_community.graphs.networkx_graph.NetworkxEntityGraph object at 0x000001E7BF8FE4A0>\n",
            "[('TV', 'None', 'is broken'), ('TV', 'customer assistance', 'needs'), ('TV', 'weird sounds', 'makes'), ('TV', 'black', 'goes'), ('warranty number', 'A512423', 'is')]\n"
          ]
        }
      ],
      "source": [
        "# NetworkX Entity graph\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nx.draw(conversation_with_kg.memory.kg, with_labels=True)\n",
        "# plt.show()\n",
        "\n",
        "print(conversation_with_kg.memory.kg)\n",
        "print(conversation_with_kg.memory.kg.get_triples())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Unn0IX14v0SB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjqlw-Q2HDLc"
      },
      "source": [
        "## Entity Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Ud227jNMHEtO"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI, ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationEntityMemory\n",
        "from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "hWZneigxHwd0",
        "outputId": "f5d26bce-4cb1-4198-b2ef-6ed96b4fd912"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n{entities}\\n\\nCurrent conversation:\\n{history}\\nLast line:\\nHuman: {input}\\nYou:'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## The propmpt\n",
        "ENTITY_MEMORY_CONVERSATION_TEMPLATE.template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "8bwvmRCtHPmD"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature=0,\n",
        "             max_tokens = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "cXd58z9dHVxQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=llm)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "-PhxTkMuHWUN",
        "outputId": "0c6eeb84-c7d2-434c-ce58-1fc413d8e9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Dhameem': '', 'TV': ''}\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Last line:\n",
            "Human: Hi I am Dhameem. My TV is broken but it is under warranty.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" I'm sorry to hear that your TV is broken, Dhameem. It's great that it's still under warranty, though. Have you contacted the manufacturer or the store where you purchased it to see if they can help you with repairs or a replacement?\""
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Hi I am Dhameem. My TV is broken but it is under warranty.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Osa-NHDtJxUW",
        "outputId": "4473e9b6-db23-4a1f-d688-191cf0eac8ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Dhameem': \"Dhameem's TV is broken but it is under warranty.\", 'A512453': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi I am Dhameem. My TV is broken but it is under warranty.\n",
            "AI:  I'm sorry to hear that your TV is broken, Dhameem. It's great that it's still under warranty, though. Have you contacted the manufacturer or the store where you purchased it to see if they can help you with repairs or a replacement?\n",
            "Last line:\n",
            "Human: How can I get it fixed. The warranty number is A512453\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' You can contact the manufacturer or the store where you purchased the TV and provide them with your warranty number, A512453. They should be able to assist you with getting it fixed or replaced.'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"How can I get it fixed. The warranty number is A512453\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKn0evo4KqnV",
        "outputId": "5dd52902-e597-47be-c5c3-652e041cac9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Dhameem', 'A512453']"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.memory.entity_cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "H0VpELTyJ8Hn",
        "outputId": "b2b57c79-1325-444d-fd4b-3e7315e576b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Dave': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi I am Dhameem. My TV is broken but it is under warranty.\n",
            "AI:  I'm sorry to hear that your TV is broken, Dhameem. It's great that it's still under warranty, though. Have you contacted the manufacturer or the store where you purchased it to see if they can help you with repairs or a replacement?\n",
            "Human: How can I get it fixed. The warranty number is A512453\n",
            "AI:  You can contact the manufacturer or the store where you purchased the TV and provide them with your warranty number, A512453. They should be able to assist you with getting it fixed or replaced.\n",
            "Last line:\n",
            "Human: Can you send the repair person call Dave to fix it?.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" I'm sorry, I am not able to send a repair person to your location. However, you can contact the manufacturer or the store where you purchased the TV and request for a repair person to be sent to your location.\""
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Can you send the repair person call Dave to fix it?.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUQxtMWVKUCe",
        "outputId": "91365981-ceff-4860-ae0d-c05bc2274951"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Dave']"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.memory.entity_cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duh46CpJKyRz",
        "outputId": "3487d2e3-3133-4d8c-9fc2-f10f64237f6f"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'ConversationEntityMemory' object has no attribute 'store'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[65], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m----> 2\u001b[0m pprint(\u001b[43mconversation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'ConversationEntityMemory' object has no attribute 'store'"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmCSoJb9LnYY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "006a8a6fc4f8474ba2063a116ddc963f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8154b1c216c498ab7d6978606bf611d",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e6c419b295f400ea6323c610b5e2c4a",
            "value": 456318
          }
        },
        "0a670fca265945fe87396b415232e526": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1664ded6d6b14a7fad1a18da32d47894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1af10c8140ca45ca93d9d17c8838ad47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23f215959688415b8582853ac96f1144": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "294d40e209fa47d3aa6357df45d1ceb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e0054d0438413c9bbaa10c018d85d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_534bb68419fb4fe4bb377850e3b8a830",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf60abc24b6a4e1db4c383c952842fd1",
            "value": 1355256
          }
        },
        "371e23a9a1424398805b583a4088f83d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d96be2040d54e5a8abda678435f6f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_832e4d537ce54ec791e29fee8a2ce3f6",
            "placeholder": "",
            "style": "IPY_MODEL_dbc7933ed137433bab975298a70d953c",
            "value": " 665/665 [00:00&lt;00:00, 21.2kB/s]"
          }
        },
        "443ef22d1c75447ba102691484be9834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccbf5cf9e32f422c97cf7a7fb02c7629",
            "placeholder": "",
            "style": "IPY_MODEL_e9560ca48182474496be72c3d8a40389",
            "value": "Downloading ()olve/main/vocab.json: 100%"
          }
        },
        "4a6e90173c674da8a145cdf27a6dd9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_371e23a9a1424398805b583a4088f83d",
            "placeholder": "",
            "style": "IPY_MODEL_4c4ec72e580d49808266ea565a31df54",
            "value": "Downloading ()/main/tokenizer.json: 100%"
          }
        },
        "4c4ec72e580d49808266ea565a31df54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e6c419b295f400ea6323c610b5e2c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5100925d892348cc89623b3d3ea992d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53448a30fa6b4618a8f2371e27335cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e56d1dd2e4c945bca7ee594d17b4cdf6",
            "placeholder": "",
            "style": "IPY_MODEL_1af10c8140ca45ca93d9d17c8838ad47",
            "value": "Downloading ()lve/main/config.json: 100%"
          }
        },
        "534bb68419fb4fe4bb377850e3b8a830": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588ca8e6340349c88329bdf36aae75d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a991f346ca94bfe9c6b81d00a9a7f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76994b445a264815b6c39dd0f2de2906",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66b8a9376e154d96b711067a076a75b0",
            "value": 1042301
          }
        },
        "66b8a9376e154d96b711067a076a75b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69bfad76a96b4908ad84f52e6fd822a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bbe81ae24c145738afa1db70df4edd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a6e90173c674da8a145cdf27a6dd9d9",
              "IPY_MODEL_35e0054d0438413c9bbaa10c018d85d3",
              "IPY_MODEL_a0b9cd7c7f2346d486f58c28a878456b"
            ],
            "layout": "IPY_MODEL_ce377f4c56964e13a6f9b1b42c671aaf"
          }
        },
        "6f100dc6ac184f4d8fe4dea27191c406": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71581e44ed1b47829bea8a80a94880b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e167df20187a41e69992b7f03ab2ec20",
            "placeholder": "",
            "style": "IPY_MODEL_1664ded6d6b14a7fad1a18da32d47894",
            "value": " 456k/456k [00:00&lt;00:00, 3.37MB/s]"
          }
        },
        "76994b445a264815b6c39dd0f2de2906": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b32196b6803467ab588d42ff3f09a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e21de8f619459bafb719aa1d4cc714",
            "placeholder": "",
            "style": "IPY_MODEL_294d40e209fa47d3aa6357df45d1ceb7",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 7.92MB/s]"
          }
        },
        "832454f6fd694d7eb94059006ac652eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f51c7606d84a479e0cb1409708fe8d",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69bfad76a96b4908ad84f52e6fd822a9",
            "value": 665
          }
        },
        "832e4d537ce54ec791e29fee8a2ce3f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8af2c451765e45a6af54eef59464dba6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e21de8f619459bafb719aa1d4cc714": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c49455f7f8a4b68b79a5ce2347f308e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53448a30fa6b4618a8f2371e27335cfb",
              "IPY_MODEL_832454f6fd694d7eb94059006ac652eb",
              "IPY_MODEL_3d96be2040d54e5a8abda678435f6f0d"
            ],
            "layout": "IPY_MODEL_588ca8e6340349c88329bdf36aae75d6"
          }
        },
        "a0b9cd7c7f2346d486f58c28a878456b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8af2c451765e45a6af54eef59464dba6",
            "placeholder": "",
            "style": "IPY_MODEL_23f215959688415b8582853ac96f1144",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 9.88MB/s]"
          }
        },
        "ab8f3eb40e3d4f2da3793fd07347709e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4d8bfaaf29841af9f61a74ff7a739ce",
              "IPY_MODEL_006a8a6fc4f8474ba2063a116ddc963f",
              "IPY_MODEL_71581e44ed1b47829bea8a80a94880b4"
            ],
            "layout": "IPY_MODEL_dce89c2933004b689c4b29b8e42cdecf"
          }
        },
        "bf60abc24b6a4e1db4c383c952842fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8154b1c216c498ab7d6978606bf611d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccbf5cf9e32f422c97cf7a7fb02c7629": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce377f4c56964e13a6f9b1b42c671aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d8bfaaf29841af9f61a74ff7a739ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f100dc6ac184f4d8fe4dea27191c406",
            "placeholder": "",
            "style": "IPY_MODEL_5100925d892348cc89623b3d3ea992d6",
            "value": "Downloading ()olve/main/merges.txt: 100%"
          }
        },
        "dbc7933ed137433bab975298a70d953c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dce89c2933004b689c4b29b8e42cdecf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e01acd08af8c49e9a157304f854a2dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_443ef22d1c75447ba102691484be9834",
              "IPY_MODEL_5a991f346ca94bfe9c6b81d00a9a7f5d",
              "IPY_MODEL_7b32196b6803467ab588d42ff3f09a80"
            ],
            "layout": "IPY_MODEL_0a670fca265945fe87396b415232e526"
          }
        },
        "e167df20187a41e69992b7f03ab2ec20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f51c7606d84a479e0cb1409708fe8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e56d1dd2e4c945bca7ee594d17b4cdf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9560ca48182474496be72c3d8a40389": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
